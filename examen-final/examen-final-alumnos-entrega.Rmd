---
title: "Examen final - Otoño 2020"
author:
- Bruno Gonzalez - 150370
- Eduardo Moreno - 151280
output:
  html_document: default
  pdf_document: default
---

**Entrega:** Enviar la carpeta que el codigo de solución (.Rmd y funciones
auxiliares) a mas tardar el 15 de Diciembre antes de las 12:00pm (mediodia), por
correo electrónico con el título fundamentos-final, un solo documento por
equipo. No se aceptarán entregas extemporáneas. Será mejor entregar un examen resuelto parcialmente, que no entregar nada.

**Instrucciones:**
  
* Tus respuestas deben ser claras y debes explicar los resultados, incluye
también tus procedimientos/código de manera ordenada, y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas,...), revisa la sección de visualización en las notas.

* Las sesiones del Martes 8 y Jueves 10 de Diciembre a las 10 am, serán espacios para resolver dudas que puedan surgir del exámen.

* No pueden compartir soluciones entre diferentes equipos, o alumnos del grupo 001 de esta misma materia.

* Al entregar este examen afirmas que el trabajo se realizó sólo con tu
compañero de equipo. El material que utilizaste para apoyarte consistió de las notas en clase (pdf en canvas), el codigo fuente de las notas en el repositorio de Github.

* Al entregar estás dando tu consentimiento para que bajo sospecha y suficiente evidencia de copia se anule tu evaluación.

# Preparación de ambiente

Asegurate de tener instalado los paquetes que usamos más en las notas del curso. 
En particular, si usas `renv` como manejador de ambientes puedes instalarlos con las instrucciones de abajo. Sólo necesitarías descomentarlas.

```{r, echo = TRUE}
# renv::install("tidyverse")
# renv::install("patchwork")
# renv::install("nullabor")
# renv::install("scales")
# renv::install('diegovalle/mxmaps')
# renv::install("nleqslv")
# renv::snapshot()

# Escribe las claves unicas de ambos miembros del equipo, para generar una
# semilla de numeros aleatorios.
claves_unicas <- c(151280, 150370)
set.seed(min(claves_unicas))
```

  
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(patchwork)
library(nullabor)
library(mxmaps)
library(scales)
library(nleqslv)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE, 
                      fig.align = 'center', cache=TRUE, fig.height = 3,
                      out.width =  "99%")
comma <- function(x) format(x, digits = 2, big.mark = ",")

```
 
 
# Modelos de conteo 

En el curso hemos estudiado las variables aleatorias Gaussianas para modelar eventos aleatorios compuestos de pequeños, pero controlados, efectos. También hemos utilizado variables aleatorias Binomiales para modelar tasas de éxito de algún evento binario de interés. En el contexto Bayesiano, hemos utilizado las distribuciones Beta, Gamma-Inversa, y Normal para realizar análisis conjugado con estos modelos. 

En este mini-proyecto, ilustraremos otra familia de distribuciones muy cómunes en la práctica. En particular, veremos la distribución **Poisson** como unmodelo de conteo. Es decir, una variable aleatoria Poisson nos sirve para modelar el número de ocurrencias de un evento en un periodo (tiempo) o área (espacio) base.

Decimos que $x|\theta \sim \textsf{Poisson}(\theta)$ si los eventos ocurren de manera independiente y a una tasa constante. La función de masa de probabilidad 
esta dada por

$$ p(X = k \, | \, \theta) = \frac{\theta^k \, e^{-\theta}}{k!},$$

donde sabemos que 

$$ \mathbb{E}[x|\theta] = \theta, \qquad  \mathbb{V}[x|\theta] = \theta $$

Al examinar la base de la función de masa de probabilidad notamos que un 
candidato para un anålisis conjugado es una distribución Gamma. Es decir, 
un candidato *natural* para una distribución previa para $\theta$ es 

$$\theta \sim \textsf{Gamma}(\alpha, \beta),$$

donde la densidad está dada por

$$ p(\theta) \propto \theta^{\alpha - 1} \, e^{-\beta \, \theta},$$

y tenemos los siguientes momentos 

$$\mathbb{E}[\theta] = \frac\alpha\beta, \qquad  \mathbb{V}[\theta] = \frac{\alpha}{\beta^2}.$$ 

---

**Pregunta 1)** Para una muestra $X_1, \ldots, X_n \overset{iid}{\sim} \textsf{Poisson}(\theta),$ determina la distribución posterior de $\theta,$ y calcula media y varianza de la distribución posterior. ¿Podríamos escribir la media posterior como un promedio ponderado entre datos e información previa? ¿Cómo interpretas los hiper-parámetros $(\alpha, \beta)?$

$$
\begin{align}
\Pi (\theta \mid x_1 , \dots, x_n) 
&\propto \Pi (x_1, \dots, x_n \mid \theta) \cdot \Pi (\theta) \\
&\propto \prod_i{\Pi(x_i \mid \theta)} \cdot \Pi(\theta) \\
&\propto \prod_i{\frac{\theta^{x_i} e^{-\theta}}{x_i!}} \cdot \theta^{\alpha-1}e^{-\beta \theta} \\
&\propto \frac{\theta^{\sum{x_i}}e^{-n\theta}}{\prod{x_i!}} \cdot \theta^{\alpha-1}e^{-\beta \theta} \\
&\propto \theta^{\alpha + \sum{x_i} - 1}e^{-\theta(\beta + n)}
\end{align}
$$
De lo anterior se puede ver que 

$$
\Pi (\theta \mid x_1 , \dots, x_n)\sim Gamma(\alpha + \sum{x_i}, \beta + n)
$$
Así,

$$
E[\theta \mid x_1 , \dots, x_n] = \frac{\alpha + \sum{x_i}}{\beta + n} \\
Var[\theta \mid x_1 , \dots, x_n] = \frac{\alpha + \sum{x_i}}{(\beta + n)^2} 
$$
Sí se puede ver como un promedio entre los datos y el parámetro $\alpha$. Entre más datos sean más peso tendrán en la posterior. En cambio si los datos $n \to 0$, la posterior será igual a la distribución a priori.
Además, interpretamos al parámetro $\alpha$ como la cantidad de éxitos y a $\beta$ como la cantidad de casos totales. Por lo que, el "valor esperado es el valor esperado éxitos".


---

Otra variable aleatoria de conteo relevante es la **Binomial Negativa.** Esta distribución sirve para modelar el número de éxitos en una secuencia de experimentos Bernoulli antes de encontrar un número específico de fracasos. 

Decimos que $X|\alpha, \beta \sim \textsf{Neg-Bin}(\alpha, \beta),$ donde $X$ es el número de éxitos que contamos antes de $\alpha$ fracasos, cuando cada fracaso ocurre con probabilidad $\frac{\beta}{\beta + 1}.$ La función de masa de probabilidad se escribe

$$ p(X = k \, | \, \alpha, \beta) = {\alpha + k -1 \choose k} \left(\frac{\beta}{\beta + 1}\right)^\alpha \left(\frac{1}{\beta + 1}\right)^k.$$

Nota que 
$${\alpha + k -1 \choose k} = {\alpha + k -1 \choose \alpha -1},$$
es decir, el número de formas que puedes acomodar $\alpha - 1$ fracasos es igual al número de formas que puedes acomodar $k$ éxitos cuando realizaste $\alpha + k-1$ experimentos y todos los experimentos son independientes. Por otro lado, la definición es
$${\alpha + k -1 \choose k} = \frac{(\alpha + k - 1)!}{k! \, (\alpha - 1)!}.$$
donde $k! = k \times k-1 \times k-2 \times \cdots \times 1,$ y la función Gamma satisface $$\Gamma(\alpha) = (\alpha - 1)!.$$

---

**Pregunta 2)** Bajo el modelo conjugado que escribiste en la pregunta 1, calcula 
la **distribución predictiva previa** para una observación Poisson. Es decir, calcula 
$$p(y) = \int \textsf{Poisson}(y \,| \,\theta) \textsf{Gamma}(\theta \, | \, \alpha, \beta) \, \text{d}\theta.$$


$$
\begin{align}
p(y) &= \int_0^{\infty} \frac{\theta^y e^{-\theta}}{y!} \cdot
\frac{\beta^\alpha \theta^{\alpha-1} e^{-\beta \theta}}{\Gamma(\alpha)} d\theta \\
&= \frac{\beta^\alpha}{\Gamma(\alpha)y!} 
\int_0^\infty\theta^{y+\alpha -1}e^{-\theta(\beta +1)}d\theta
\end{align}
$$
Sabemos que:
$$ \Gamma(z) = \int_0^\infty t^{z-1}e^{-t}dt$$
Entonces si:

$$
t = \theta(\beta +1)\\
\Rightarrow \theta = \frac{t}{\beta +1} \\
d\theta = \frac{1}{\beta +1}dt
$$
Así:
$$
\begin{align}
&= \frac{\beta^\alpha}{\Gamma(\alpha)y!} 
\int_0^\infty\frac{t}{\beta +1}^{y+\alpha -1}e^{-t} \frac{1}{\beta +1}dt \\
&= \frac{\beta^\alpha}{\Gamma(\alpha)y!}\cdot\frac{1}{(\beta+1)^{y+\alpha}} \int_0^\infty t^{y+\alpha -1}e^{-t}dt \\
&= \frac{\beta^\alpha}{\Gamma(\alpha)y!}\cdot\frac{1}{(\beta+1)^{y+\alpha}} \Gamma(y+\alpha) \\
&= \frac{\Gamma(y+\alpha)}{\Gamma(\alpha)y!}  \frac{\beta^\alpha}{(\beta+1)^{y+\alpha}} \\
&=\frac{(y+\alpha-1)!}{(\alpha-1)!y!} \left(\frac{\beta}{\beta+1}\right)^\alpha \left(\frac{1}{\beta+1}\right)^y \\
&=\binom{y+\alpha-1}{y} \left(\frac{\beta}{\beta+1}\right)^\alpha \left(\frac{1}{\beta+1}\right)^y
\end{align}
$$


Verifica tu cálculo utilizando las reglas probabilidad condicional. En especifico, utiliza

$$ p(y) = \frac{p(y|\theta)p(\theta)}{p(\theta|y)}.$$
Tenemos que:

$$
\begin{align}
p(y) &= \frac{ \frac{\theta^y e^{-\theta}}{y!} \frac{\beta^\alpha\theta^{\alpha-1}e^{-\beta\theta}}{\Gamma(\alpha)}}
{\frac{(\beta+1)^{\alpha+y}\theta^{\alpha+y-1}e^{-(\beta+1)\theta}}{\Gamma(\alpha+y)}} \\
&= \frac{\Gamma(\alpha+y)}{\Gamma(\alpha)y!} \frac{\beta^\alpha}{(\beta+1)^{\alpha + y}}\theta^0e^0 \\
&=\frac{(y+\alpha-1)!}{(\alpha-1)!y!} \left(\frac{\beta}{\beta+1}\right)^\alpha \left(\frac{1}{\beta+1}\right)^y \\
&=\binom{y+\alpha-1}{y} \left(\frac{\beta}{\beta+1}\right)^\alpha \left(\frac{1}{\beta+1}\right)^y
\end{align}
$$
¿Qué distribución marginal tiene $y$ bajo el modelo conjugado?

Es una distrubución binomial negativa, por lo tanto
$$ y \sim BinNeg(\alpha,\beta)$$

---

En la práctica, es útil extender el modelo Poisson como sigue
\begin{align}
  x_i | t_i, \theta &\sim \textsf{Poisson}(\lambda_i), \\
  \lambda_i &= t_i \theta, 
\end{align}

donde la tasa de ocurrencia $\lambda_i$ ha sido descompuesta en un producto que incorpora la exposición $t_i$ y una tasa de ocurrencia por unidades expuestas $\theta.$ En este contexto usualmente tenemos observaciones para $x_i$ y $t_i$ pues conocemos el parámetro de exposición. Por ejemplo, si $x_i$ es el número de personas que se enferman de gripe en la $i$-ésima ciudad en un año, entonces $\theta$ denota la tasa anual por persona de enfermarse de gripe en una población de tamaño $t_i$.

**Pregunta 3)** Supongamos que tenemos datos $X_1, \ldots, X_n \sim
\textsf{Poisson}(\lambda_i),$ con $\lambda_i = t_i \theta$ para $i = 1, \ldots, n.$ Utilizando el modelo conjugado, ¿cuál es la distribución posterior de $\theta?$


$$
\begin{align}
\Pi (\theta \mid x_1 , \dots, x_n) 
&\propto \Pi (x_1, \dots, x_n \mid \theta) \cdot \Pi (\theta) \\
&\propto \prod_i{\Pi(x_i \mid \theta)} \cdot \Pi(\theta) \\
&\propto \prod_i{\frac{(\theta t_i)^{x_i} e^{-\theta t_i}}{x_i!}} \cdot \theta^{\alpha-1}e^{-\beta \theta} \\
&\propto \theta^{\sum{x_i}}e^{-\theta\sum t_i} \cdot \theta^{\alpha-1}e^{-\beta \theta} \\
&\propto \theta^{\alpha + \sum{x_i} - 1}e^{-\theta(\beta + \sum t_i)}
\end{align}
$$

Por lo tanto, la distribución posterior es:
$$
\Pi (\theta\mid x_1 ,\dots,x_n)\sim Gamma(\alpha + \sum{x_i}, \beta + \sum t_i)
$$

---

# Caso de estudio: Tasas de mortalidad

El INEGI publica para cada año los registros de fallecimiento junto con la causa
principal de muerte. En esta sección utilizaremos los modelos descritos
anteriormente para inferir tasa de fallecimiento por Neumonía para cada uno de
los municipios/delegaciones del país. Contamos con los últimos 5 años de los
registros de defunción.

---

### Carga y preparación de datos


**Pregunta 4)** Empecemos explorando los datos. Carga los datos para un año que
elijas. Encontrarás en los archivos en `datos/poblacion/defunciones/<año>` los
registros de defunciones por Neumonía para el `<año>` que escojas.

```{r carga defunciones de un año, message=FALSE}
defunciones <- read_csv("./datos_examen/poblacion/defunciones/2019/defunciones_registradas.csv")


str(defunciones)
map_int(defunciones[,1:5], ~length(unique(.x)) )

```
* El dataset contiene $5$ variables y tenemos un total de $30,327$ observaciones.

* Observemos que tenemos $33$ entidades, lo cual hace un poco de ruido, ya que, la República Mexicana está constituída por $32$ entidades federativas.

* En el dataset se tiene información de $314$ municipios, de acuerdo a informaicón declarada por el [INEGI](http://cuentame.inegi.org.mx/territorio/division/default.aspx?tema=T#:~:text=Para%20gobernar%2C%20organizar%20y%20administrar,todo%20el%20pa%C3%ADs%202%20457.) hay un total de $2,465$ municipios, por lo que nuestra muestra contiene aproximadamente el $12\%$ de ellos.

* Para el sexo aparecen $3$ categorías (intuitivamente diríamos que es Masculino, Femenino y No declarado).

* Tenemos $7$ grupos de edad, los cuales son los siguientes:

```{r defunciones por edad}
defunciones$edad_grupos %>% unique
```


* $[3, 6)$
* $[6, 12)$
* $[12, 18)$
* $[18, 25)$
* $[25, 64)$
* $[64, \inf)$

Para el tema de los $33$ estados analicemos los valores:
```{r defunciones por estado}
defunciones$entidad %>% unique() %>% sort()
```
Nótese que se tiene una entidad $999$, que por intuición indicaríamos que es una Entidad no identificada.

Y ahora para la variable sexo:
```{r defunciones por genero}
defunciones$sexo %>% unique() %>% sort()
```

Nuestra hipótesis era casi correcta, tenemos un tercer sexo el cual es NaN, que nos sugiere que el usuario no se identificó con alguno de los 2 sexos o bien, no quiso declarar esa información.

Ahora analicemos un poco la variabilidad de los datos.

```{r grafica defunciones por año}
defunciones %>% 
  ggplot(data = ., aes(x = edad)) +
  geom_boxplot(aes(color = sexo)) +
  ggtitle('Edad por sexo declarado') +
  xlab('Edad') +
  ylab('Frecuencia relativa')

defunciones %>% colnames()
```
Es difícil analizar la dispersión de las edades por sexo debido a la existencia de $2$ valores atípicos, los cuales equivalen a la edad $1,000$ años, lo cual no hace sentido, pues no existe ningún registro de una persona en la historia de la humanidad que haya sobrevivido a $1,000$ años. Suponemos que para dichas observaciones el individuo no quiso declarar su edad o bien hubo un  error en el registro de la captura del dato. A continuación analizaremos las edades sin dichos valores.

```{r defunciones sin atipicos}
defunciones %>% 
  filter(edad < 250) %>% 
  ggplot(data = ., aes(x = edad)) +
  geom_boxplot(aes(color = sexo)) +
  ggtitle('Edad filtrada por sexo declarado') +
  xlab('Edad') +
  ylab('Frecuencia relativa')
```

Realizando el filtro correspondiente es un poco más "sencillo" (es una palabra que no nos gusta utilizar, ya que es relativo a la persona) analizar la dispersión de la edad para las personas:
* La mediana de edad para mujeres es mayor que para los hombres, sin embargo, ambas distribuciones son muy similares.
* Para el sexo no declarado la edad únicamente es 0, por lo que, para dichas observaciones el individuo no quiso declarar su sexo ni edad.


En relación a la variable `entidad`, estos son nuestros comentarios:
```{r defunciones por entidad}
defunciones %>% 
  select(entidad) %>% 
  table() %>% 
  sort(decreasing = TRUE)
```

Es difícil saber qué Estado representa cada número, ya que, no se cuenta con un diccionario de datos. Por ahora solamente se puede indicar que el estado $9$, es el que tiene un mayor peso en el dataset.


**Pregunta 5)** De igual forma, carga los datos de población que encontrarás en
`datos_examen/poblacion/demograficos`. Por el momento, no necesitamos los grupos
de edad (aunque despúes los utilizaremos). Por ahora escribe el codigo necesario 
para calcular el tamaño de la población en cada uno de los municipios.

```{r carga demograficos, message=FALSE}
poblacion <- read_csv("./datos_examen/poblacion/demograficos/poblacion_municipios_edad.csv")

poblacion <- poblacion %>% 
  mutate(pob_tot = p_0a2+p_3a5+p_6a11+p_12a17+p_18a24+p_25a64+pob65_mas)

```

**Pregunta 6)** Ahora necesitamos *cruzar* las tablas de defunciones y población para crear una tabla con ambos registros. Para esto necesitarás la función `dplyr::full_join`.


```{r cruce defunciones y poblacion, message=FALSE}
# Primero se agrupan los datos de defunciones por municipio
defunciones_mun <- defunciones %>% 
  group_by(entidad, municipio) %>% 
  count(name = 'defunciones')

datos = poblacion %>% 
  left_join(defunciones_mun, by=c('entidad', 'municipio'))

```

**Pregunta 7)** Con esto tendrás conocimiento de cómo cargar la información
relevante (número de defunciones y población total en cada municipio). Sin
embargo, tenemos información para las defunciones de los últimos 5 años. Carga
la información que encontrarás en `/defunciones/` y agrupa de tal forma que
tengas una tabla como la anterior. **Importante: ** Para fines de este proyecto
no necesitamos los conteos por año, sólo el agrupado. Es decir, el número de
defunciones totales de los 5 años por municipio.


```{r carga masiva, message = FALSE, warning = FALSE}
# En la funcion cargar_defunciones, en caso de error
# Por favor escribir como parámetro la dirección donde se entuentran 
# los archivos de defunciones (ej: "./datos_examen/poblacion/defunciones/")
cargar_defunciones <- function(path="./datos_examen/poblacion/defunciones/"){
  x <- list.files(path, full.names=TRUE, recursive = TRUE)
  def_acum <- NULL
  for (file in x){
    def <- read_csv(file)
    def_acum <- def_acum %>% bind_rows(def)
  }
  return(def_acum)
}
defunciones <- cargar_defunciones()

defunciones_mun <- defunciones %>% 
  group_by(entidad, municipio) %>% 
  count(name = 'muertes_neum')

full_data = poblacion %>% 
  left_join(defunciones_mun, by=c('entidad', 'municipio')) %>% 
  replace_na(list(muertes_neum=0)) %>% 
  mutate(tasa_mort = muertes_neum/pob_tot)
```

--- 

### Cálculo de estadístico de interés

Lo que nos interesa en particular son las tasas de mortalidad anual en los
municipios del país. Para esto utilizaremos el modelo Poisson que vimos en la
primera parte. Si denotamos por $y_i$ el número total de defunciones por neumonia
en el $i$-ésimo municipio; $\theta_i,$ la tasa de mortalidad por individuo por
año, entonces 

$$ y_i \, | \, n_i, \theta_i \sim \textsf{Poisson}(\lambda_i),$$

donde $n_i$ denota la población total del municipio $i$-ésimo y 
$\lambda_i$ la tasa con la que ocurren las  muertes por neumonía en el periodo
observado para la población del municipio $i$-ésimo.

**Pregunta 8)** ¿Cómo escribirías $\lambda_i$ en función de $\theta_i$?

Ahora, utilizaremos un mapa para ver si podemos observar algún patrón en las
tasas de mortalidad por individuo por año $\theta_i.$ Por ejemplo, podríamos
esperar que algunas zonas del país concentren las tasas mas altas. Por ejemplo,
podemos crear mapas con los municipios con las tasas mas bajas y altas. Digamos
que sólo queremos ver el 25\% mas bajo y alto. Los mapas los obtenemos con las
funciones `mxmaps::mxmunicipio_choropleth`.

La estructura que necesita esta función es una tabla con una columna que se 
llame `region` donde venga el codigo identificador del municipio. Por ejemplo, 
para el municipio `001` en el estado `24` el codigo de region será `24001`. Otra 
columna necesaria es el valor con el que "coloreará" el municipio en el mapa y
se tiene que llamar `value` y puede ser una variable `Boolean` o `double`. 

**Pista.** Para este punto, podrías necesitar la función `dplyr::row_number`. De
igual forma podrías ocupar una indicadora para decir cuáles son los municipios
con las tasas mas altas y cuáles son los que tienen las mas bajas. Al final,
podrías presentar esto como dos mapas separados.

Respuesta:
La manera de representar $\lambda_i$ en función de $\theta_i$ es la siguiente:

$$ \lambda_i(\theta_i) = 5*\theta_i*n_i $$

```{r mapa}
datos2 <- full_data %>% 
  mutate(region = paste0(entidad,municipio),
         mortalidad = ((muertes_neum)/pob_tot), 
         orden = row_number(mortalidad)/nrow(full_data),
         value = ifelse(orden<0.75,
         ifelse(orden<0.25,"1_Menos_casos","2_Med"),
         "3_Mas_casos"))

mxmunicipio_choropleth(datos2)

```

Es muy difícil encontrar un patrón claro para las defunciones por neumonía. Ya que se tiene estados en donde se tiene las tasas más altas y bajas al mismo tiempo.

¿Qué observas? No hay patrón tan claro. Especialmente si observamos lo que
sucede en Chihuahua, Durango y Coahuila, donde tenemos municipios de ambas
categorías. ¿Cómo puede ser que un mismo estado tenga las tasas mas altas y
bajas al mismo tiempo?

¡El problema es el tamaño de muestra! Considera un municipio de 1,000
habitantes. Muy probablemente en 5 años no veamos una muerte por neumonía, lo
cual convertiría la tasa observada en 0. Sin embargo, si ocurriera una muerte
entonces la tasa sería de 1/5,000 por año, lo cual sería muy elevado con
respecto a otros municipios con poblaciones grandes y mayor número de casos.

## Inferencia Bayesiana para tasa de mortalidad

Utilizaremos inferencia Bayesiana para regularizar el problema. Seguiremos 
suponiendo que 

$$ y_i \, | \, n_i, \theta_i \sim \textsf{Poisson}(\lambda_i),$$

pero ahora necesitamos una distribución previa para $\theta_i.$ Sabemos, por lo
anterior, que el modelo Poisson-Gamma es conjugado. Por lo tanto requerimos una
distribución Gamma. Sólo falta elicitar los hiperparámetros. 

No todos somos expertos en salud ni tenemos conocimiento previo. Sin embargo,
podemos visitar esta [página](https://ourworldindata.org/pneumonia) para darnos
una idea de las tasas de mortalidad por neumonía en el resto del mundo.

A continuación se muestra las tasas de mortalidad para los últimos años para
algunos paises y la region de America Latina y el Caribe.

```{r, echo = FALSE}
knitr::include_graphics('imagenes/mortalidad-neumonia.png')
```

Considera los siguientes puntos: 
  
  - Las tasas anteriores han sido calculadas con un método que incorpora la
  estructura demográfica de cada país y la estandariza con respecto a la
  pirámide poblacional mundial. En nuestro ejemplo, nuestras tasas no serán
  ajustada de tal forma (este método se conoce en inglés como *age-standarized
  mortality rates*).
  - Las tasas reportadas tienen una base distinta, pues son reportadas con respecto
  a una población de 100,000 habitantes. Es decir, son tasas de mortalidad
  anuales para poblaciones de 100K habitantes. Por ejemplo, un valor de 5
  significa que en promedio 5 habitantes por cada 100K mueren de neumonia al
  año.
  
**Pregunta 9)** Con esto en mente, escribe los límites necesarios para encontrar
una distribución Gamma adecuada. Encuentra la solución al sistema de ecuaciones
no lineales por medio de la función `nleqslv::nleqslv`. Escribe tu razonamiento 
para seleccionar dichos valores. 

La tasa de habitantes fallecidos por neumonía (filtrado por años tomando en cuenta únicamente del año $2015$ hasta el $2017$) presenta un comportamiento uniforme (no en el sentido estricto, pero sí de una forma bastante aproximada) a lo largo del periodo de estudio en este proyecto para los distintos grupos de edades, por lo que, se decidió dar como cota superior el promedio de la tasa de mortalidad para el rango de edad "$70+$ years old", ya que son los máximos alcanzado y como límite inferior el promedio de las tasa del rango "$5-14$ years old", pues son las mínimas observadas.

```{r elicitacion}
### promedio de tasa de mortalidad para grupos de edad mayores y menores
cot_sup <- mean(c(184.31, 181.42, 178.51))
cot_min <- mean(c(1.14, 1.12, 1.12))

limits <- c(cot_min, cot_sup)/(10**5)

gamma.limits <- function(x){
  # reparametrizamos para que el problema sea mas "fácil" en términos numéricos.
  log_alpha <- x[1]
  log_beta  <- x[2]
  
  # definimos las cotas de probabilidad
  p_cota <- 0.1
  c(    pgamma(limits[1], exp(log_alpha), rate = exp(log_beta)) - p_cota,
    1 - pgamma(limits[2], exp(log_alpha), rate = exp(log_beta)) - p_cota)
}

initial_guess <- c(log(1), log(1))

results <- nleqslv(initial_guess, gamma.limits)

params.prior <- exp(results$x)

rm(cot_sup, cot_min, results)
```

**Pregunta 10)** Grafica los histogramas de una variable aleatoria Gamma con los valores
iniciales para el problema de optimización y con los finales de dicho algorimo.
Esto te servirá de verificación que el método funciona adecuadamente.

```{r histogramas elicitacion}
set.seed(min(claves_unicas))

# simulamos en base a la distr apriori
n_sim <- 5000
g_priori_1 <- rgamma(n_sim, initial_guess[1], initial_guess[2])
g_priori_2 <- rgamma(n_sim, params.prior[1], params.prior[2])

### juntamos los datos
data_gamma <- 
  data.frame(update = c( rep("Tipo 1", n_sim), 
                       rep("Tipo 2",n_sim)),
  value = c(g_priori_1, g_priori_2))

# graficamos
data_gamma %>%
  ggplot(aes(x = value, fill = update)) +
  geom_histogram(alpha=0.3, position = 'identity', bins = 30) +
  xlab("Tasas de mortalidad por neuomonia") +
  ylab("Frecuencia absoluta") +
  ggtitle('Simulaciones para distribucion A-priori')
  
```
En comparación de las distribuciones apriori, observamos que la segunda ("Tipo 2"), tiene un mejor comportamiento en comparación con la primera, que indica que no habrá ninguna muerte con neumonía, en contraste los datos no lo indican así.

**Pregunta 11)** ¿Cómo se compara la distribución a priori con las tasas
observadas en los municipios? Puedes utilizar histogramas para estas
comparaciones. Por otro lado, no te preocupes si no se ven identicas. El punto es
ver que nuestras creencias iniciales se ven coherentes. 

```{r message=FALSE, warning=FALSE}
# filtramos por municipios desconocidos (999)
data_neum <- full_data %>% 
  filter(municipio != 999) %>% 
  ungroup() %>%
  select(tasa_mort)

# obtenemos el plot del historico y simulacion con distribucion apriori
data.frame(muertes = c(data_neum$tasa_mort, 
                       g_priori_2),
           tipo = c(rep('Historico', length(data_neum$tasa_mort)), 
                    rep('Simulado', n_sim))) %>% 
  ggplot(aes(x = muertes, fill = tipo)) + 
  geom_histogram(alpha=0.5, position = 'identity') +
  xlab('Defunciones por neumonia') +
  ylab('Frecuencia absoluta') +
  ggtitle('Simulacion VS Historico')


rm(data_gamma, data_neum, g_priori_1, g_priori_2)
```

Se sobreestima la tasa de mortalidad por neumonía para el valor $0$, es decir, nuestra distribución apriori supone una gran supervivencia, lo cual no es respaldado por los datos, sin embargo, eso buscaremos cambiar incorporando la información de los datos con la distribución posterior.

**Pregunta 12)** Utiliza un gráfico de dispersión para comparar las tasas
observadas contra la población del municipio. ¿Qué observas? Utiliza los ejes en
escala logaritmica. Para esto checa la función: `ggplot2::scale_x_log10` y
`ggplot2::scale_y_log10`

```{r}
# comparacion de tasa de mortalidad y poblacion total
full_data %>%
  ggplot(aes(x = tasa_mort, y = pob_tot)) +
  geom_point(color = 'tomato') +
  xlab('Tasa de mortalidad') +
  ylab('Poblacion total') +
  ggtitle('Informacion a nivel municipio')

full_data %>%
  ggplot(aes(x = tasa_mort, y = pob_tot)) +
  geom_point(color = 'tomato') +
  ggplot2::scale_x_log10() +
  ggplot2::scale_y_log10() +
  xlab('Tasa de mortalidad (log)') +
  ylab('Poblacion total (log)') +
  ggtitle('Informacion a nivel municipio')
```

El primer gráfico es un poco "difícil" (las palabras difícil, fácil, sencillo,... son demasiado relativa a las características intrínsecas de los individuos) de asimilar, pues hay una gran concentración de puntos que no permiten analizar un poco el fenómeno a similar. Sin embargo, para el segundo gráfico la historia es un distinta, ya que, pareciese que este fenómeno sigue un comportamiento un tatnto exponencial, para tasas de mortalidad bajas, la población total es alta, mientras qeu para tasas de mortalidad altas, la población es baja. Todo esto con un comportamiento exponencial. Que se presente este caso, nos da la siguiente idea intuitiva:
* La neumonía no afecta de manera uniforme a la población, pues dependiendo de la estructura demográfica (en cuanto a edades) de la población, la nuemonía afectará de manera distinta a cada uno de los distintos grupos.

Cuando tenemos tamaños de población grande, la presencia de muertes por neumonía es alta, debido a la alta densidad poblacional y de manera inversa, cuando tenemos tamaños de población bajos, la presencia de muertes por neumonía es alta, debido a la baja densidad poblacional. Es relvante mencionar que tenemos presencia de valores atípicos en las colas, los cuales hacen que nuestra "hipótesis" sea falsa.

**Pregunta 13)** Ahora usaremos la distribución predictiva **previa** para explorar 
los posibles valores que tendrían los casos de muerte bajo nuestro modelo para
municipios de distintos tamaños. Para este punto considera que la predictiva es 
una mezcla de Poisson con Gamma, como se expresa en

$$p(y|n) = \int \textsf{Poisson}(y | n, \theta) \, \textsf{Gamma}(\theta|\alpha, \beta) \, \text{d}\theta.$$
o bien, la forma en especifico de la predictiva preevia. ¡Esto ya lo has
resuelto en la primera parte del examen!

Usa histogramas  para ver los números de muertes en municipios hipotéticos de
tamaño $n = 10^3, 10^4, 10^5.$

```{r, echo = FALSE}
set.seed(min(claves_unicas))

# analizamos por tamaño de poblacion
muer_103 <- rnbinom(n_sim,
                    size = 10^3*(params.prior[1]),
                    prob = (params.prior[2]/(params.prior[2]+1)))
muer_104 <- rnbinom(n_sim,
                    size = 10^4*(params.prior[1]),
                    prob = (params.prior[2]/(params.prior[2]+1)))
muer_105 <- rnbinom(n_sim,
                    size = 10^5*(params.prior[1]),
                    prob = (params.prior[2]/(params.prior[2]+1)))

# juntamos la informacion en un mismo dataframe
data_muer_sim <- data.frame(tamanio_pob = c(rep("1,000", n_sim), 
                                            rep("10,000", n_sim),
                                            rep("100,000", n_sim)),
                            value = c(muer_103, muer_104, muer_105))

# graficamos para tamaño pequeño de poblacion
data_muer_sim %>%
  filter(tamanio_pob == "1,000") %>%
  ggplot(aes(x = value, fill = tamanio_pob)) +
  geom_histogram(position = 'identity') +
  ggtitle('Simulacion defunciones por neumonia') +
  xlab('Muertes por neumonia') +
  ylab('Frecuencia absoluta')

# graficamos para tamaño mediano de poblacion
data_muer_sim %>%
  filter(tamanio_pob == "10,000") %>%
  ggplot(aes(x = value, fill = tamanio_pob)) +
  geom_histogram(position = 'identity') +
  ggtitle('Simulacion defunciones por neumonia') +
  xlab('Muertes por neumonia') +
  ylab('Frecuencia absoluta')

# graficamos para tamaño grande de poblacion
data_muer_sim %>%
  filter(tamanio_pob == "100,000") %>%
  ggplot(aes(x = value, fill = tamanio_pob)) +
  geom_histogram(position = 'identity') +
  ggtitle('Simulacion defunciones por neumonia') +
  xlab('Muertes por neumonia') +
  ylab('Frecuencia absoluta')

# graficamos y distinguimos por de poblacion
data_muer_sim %>%
  ggplot(aes(x = value, fill = tamanio_pob)) +
  geom_histogram(alpha = 0.5, position = 'identity') +
  ggtitle('Simulacion defunciones por neumonia') +
  xlab('Muertes por neumonia') +
  labs(subtitle = 'Por tamanio de poblacion')
  ylab('Frecuencia absoluta')

rm(muer_103, muer_104, muer_105, data_muer_sim)
```

Analicemos que las simulaciones obtenidas nos indican que los muertos por neumonía para cada una de las poblaciones simuladas disminuyen. Para el caso de el tamaño de población de $100,000$ pareciese una forma "unimodal" y "simétrica", pero esto sólo queda como comentario no como resultado.

**Pregunta 14)** Calcula los valores posteriores de las tasas de mortalidad bajo
nuestro modelo bayesiano y compara con los estimadores de máxima verosimilitud. 
Para esto puedes utilizar un gráfico de dispersión cómo el visto en clase o los
anteriores. ¿Observas regularización en nuestras estimaciones? ¿Qué observas si
haces un grafico como el de la pregunta 12?

$$p(y|n) = \int \textsf{Poisson}(y | n, \theta) \, \textsf{Gamma}(\theta|\alpha, \beta) \, \text{d}\theta.$$


Cabe mencionar que la distribución predictiva posterior es la siguiente:

$$ y | n \sim BN(\alpha \text{ } + \text{ } \sum_{i=1}^nx_i, \text{ } \beta \text{ } + \text{ }n)  $$
```{r message=FALSE, warning=FALSE}
set.seed(min(claves_unicas))

# filtramos por municipios desconocidos (999)
full_data_filt <- full_data %>% 
  filter(municipio != 999)

# funcion para calcular los parametros de la distribucion posterior
calcular_pars_posterior <- function(num_muertes , tam_pob, params.prior){
  
  # Parametros iniciales
  alpha_prior <- params.prior[1]
  beta_prior <- params.prior[2]
  
  # Parámetros
  alpha_post <- alpha_prior + num_muertes
  
  # beta post
  beta_post <- beta_prior + tam_pob
  # beta_post <- beta_prior + 1
  return(c(alpha_post, beta_post)) 
  }

# calculamos los parametros de la distr posterior para cada municipio
pars_post <- apply(full_data_filt[,c('muertes_neum', 'pob_tot')], 1, 
             function(x) calcular_pars_posterior(x[1], x[2],
                                                 params.prior)) %>% 
  t()

# simulamos tasas de mortalidad para cada municipio
full_data_filt$tasa_sim_post <-  apply(pars_post, 1, 
                                       function(x) rgamma(1, x[1], x[2]))


# simulamos tasas de mortalidad para cada municipio
full_data_filt %>% 
  ggplot(aes(x = tasa_sim_post, y = tasa_mort)) +
  geom_point() +
  xlab('Tasa de mortalidad simulada') +
  ylab('Tasa de mortalidad observada') +
  ggtitle('Ajuste de simulacion')

# graficamos tasas de mortalidad simuladas (posterior) y observadas en escala
# logaritmica
full_data_filt %>% 
  ggplot(aes(x = tasa_sim_post, y = tasa_mort)) +
  geom_point() +
  ggplot2::scale_x_log10() +
  ggplot2::scale_y_log10() +
  xlab('Tasa de mortalidad simulada (log)') +
  ylab('Tasa de mortalidad observada (log)') +
  ggtitle('Ajuste de simulacion - escala logaritmica')

# calculamos la tasa de mortalidad por max verosimilitud
# como suponemos que la defuncion se distribuye POISSON, entonces el estimador
# por maxima verosimlitud para theta es el promedio: 
# (numero de defunciones)/(tamaño de poblacion)
full_data_filt$tasa_sim_ver <- full_data_filt$muertes_neum/full_data_filt$pob_tot

data.frame(tasa_mort = c(full_data_filt$tasa_sim_ver, 
                         full_data_filt$tasa_sim_post)) %>% 
  mutate(Tipo = c(rep('Sim Max Ver', 2456), 
                  rep('Sim posterior', 2456))) %>% 
  ggplot(aes(x = tasa_mort, fill = Tipo)) +
  geom_histogram(alpha = 0.5) +
  xlab('Tasa de mortalidad') +
  ylab('Frecuencia absoluta') +
  ggtitle('Comparacion de simulacion')
```

Notemos un hecho importante en la gráfica "Ajuste por simulación  escala logarítmica", el cual es que para las tasas de mortalidad simuladas más altas, se vienen las tasas de mortalidad observadas más altas y de manera análoga para las más chicas. Esto es importante, pues si no fuese así, estaríamos llegando a contradicciones en el estudio. En comparación con los estimadores de máxima verosimilitud con los parámetros obtenidos por la distribución posterior, observamos que las distribuciones tienen la misma "forma", mas con el gran cambio en que para la máxima verosimilitud hay una mayor frecuencia pra las tasas más bajas a comparación de la posterior.

**Pregunta 15)** Utiliza la distribución predictiva *posterior* para verificar
el ajuste del modelo. Para esto, escoge tres municipios al azar de distintos
tamaños (chico, mediano, grande)
Grafica un histograma y compara con el número
observado de defunciones.

```{r}
set.seed(min(claves_unicas))

# calculamos el tamaño de poblacion
# chico <= 1,000
# 1,000 < mediano <= 10,000
# 10,000 < grande
full_data_filt <- full_data_filt %>% 
  mutate(tamanio = ifelse(pob_tot <= 1000, 1, 
                          ifelse(pob_tot <= 10000, 2, 3)))

# cantidad de municipios por tamaño
full_data_filt %>% 
  group_by(tamanio) %>% 
  summarise(count = n())

# seleccionamos aleatoriamente un municipio de cada tamaño
pos_chico <- sample(which(full_data_filt$tamanio == 1), 1)
pos_mediano <- sample(which(full_data_filt$tamanio == 2), 1)
pos_grande <- sample(which(full_data_filt$tamanio == 3), 1)

# obtenemos los parametros 
par_post_chico <- pars_post[pos_chico,]
par_post_mediano <- pars_post[pos_mediano,]
par_post_grande <- pars_post[pos_grande,]

# Simulamos la distribución predictiva posterior para municipio pequeño
data.frame(sim = rnbinom(1000, 
                    size = par_post_chico[2]*(params.prior[1]) + par_post_chico[1],
                    prob = (params.prior[2] + 1)/(params.prior[2] + 1 + 1) )) %>% 
  ggplot(aes(x = sim)) +
  geom_histogram() +
  geom_vline(xintercept = par_post_chico[1], color = 'red') +
  geom_text(aes(x=1.36, y=410,
                label="Defunciones observadas"), 
            colour="tomato", vjust = 1.2) +
  xlab('Defunciones por neumonia') +
  ylab('Frecuencia absoluta') +
  ggtitle('Simulacion defunciones por neumonia') +
  labs(subtitle = 'Municipio de tamanio pequenio')

# Simulamos la distribución predictiva posterior para municipio mediano
data.frame(sim = rnbinom(1000, 
                    size = par_post_mediano[2]*(par_post_mediano[1]) + par_post_mediano[1],
                    prob = (par_post_mediano[2] + 1)/(par_post_mediano[2] + 1 + 1) )) %>% 
  ggplot(aes(x = sim)) +
  geom_histogram() +
  geom_vline(xintercept = par_post_mediano[1], color = 'red') +
  geom_text(aes(x=3, y=250,
                label="Defunciones observadas"), 
            colour="tomato", vjust = 1.2) +
  xlab('Defunciones por neumonia') +
  ylab('Frecuencia absoluta') +
  ggtitle('Simulacion defunciones por neumonia') +
  labs(subtitle = 'Municipio de tamanio mediano')

# Simulamos la distribución predictiva posterior para municipio grande
data.frame(sim = rnbinom(1000, 
                    size = par_post_grande[2]*(par_post_grande[1]) + par_post_grande[1],
                    prob = (par_post_grande[2] + 1)/(par_post_grande[2] + 1 + 1) )) %>% 
  ggplot(aes(x = sim)) +
  geom_histogram() +
  geom_vline(xintercept = par_post_grande[1], color = 'red') +
  geom_text(aes(x=60, y=125,
                label="Defunciones observadas"), 
            colour="tomato", vjust = 1.2) +
  xlab('Defunciones por neumonia') +
  ylab('Frecuencia absoluta') +
  ggtitle('Simulacion defunciones por neumonia') +
  labs(subtitle = 'Municipio de tamanio grande')
```


Para las simulaciones de las defunciones por neumonía de cada municipio notemos que la la cantidad de defunciones observadas se encuentra alrededor de la media de la distribución.

## Incorporando Grupos de Edad

Se sabe que las muertes por neumonia no son uniformes y las tasas de mortalidad
son mas altas en niños y personas mayores. Ahora realizaremos el mismo análisis
considerando grupos de edad. Para esto ampliaremos nuestro modelo

$$ y_{k,i} \, | \, n_{k,i}, \theta_{k,i} \sim \textsf{Poisson}(\lambda_{k,i}),$$

donde utilizamos el sub-indice $k,i$ para denotar el $k$-ésimo grupo de edad en
el $i$-ésimo municipio.

**Pregunta 16)** Genera histogramas para cada grupo de edad y discute si el
supuesto anterior esta soportado por los datos. Para esto calcula las tasas de 
mortalidad adecuadas. Auxiliate de `ggplot2::facet_wrap`.

```{r}
# Agrupamos la información para poder tener el grupo de edad y trabajarlo con
# ggplot
datos_edad <- poblacion %>% 
    select(entidad, municipio, p_0a2:pob65_mas) %>% 
  pivot_longer(p_0a2:pob65_mas, 
               names_to = "GrupoEdad",
               values_to = "Poblacion") %>% 
  left_join(defunciones %>% 
  group_by(entidad, municipio, edad_grupos) %>% 
  count(name="Defunciones") %>% 
  mutate(GrupoEdad = recode(edad_grupos,
                            "[0,3)"="p_0a2",
                            "[3,6)"="p_3a5",
                            "[6,12)"="p_6a11",
                            "[12,18)"="p_12a17",
                            "[18,25)"="p_18a24",
                            "[25,64)"="p_25a64",
                            "[64,Inf]"="pob65_mas")),
  by=c('entidad', 'municipio', 'GrupoEdad' )) %>% 
  mutate(Defunciones = replace_na(Defunciones, 0),
    mortalidad = Defunciones/Poblacion,
    GrupoEdad = factor(GrupoEdad, 
                       levels = c("p_0a2","p_3a5","p_6a11","p_12a17",
                                  "p_18a24","p_25a64","pob65_mas")))

```

Ahora la grafica

```{r}
# graficamos diferenciando por grupo de edad
datos_edad %>% 
  ggplot() +
  geom_histogram(aes(x=mortalidad), bins=40) +
  facet_wrap(vars(GrupoEdad))

datos_edad %>% 
  group_by(GrupoEdad) %>% 
  summarise(Poblacion = sum(Poblacion))
```
Por motivos de simplicidad usaremos la misma distribución previa para cada tasa
de mortalidad asociada a grupos de edad y municipio que en los puntos anteriores. 

**Pregunta 17)** Utiliza graficos de dispersión para determinar si hay efectos
de regularización. Las ideas las encuentras arriba en la pregunta 12 y 14.

```{r vectorizacion gamma}
# obtenemos los parametros de la distr posterior para cada grupo de edad
vec_gamma <- Vectorize(rgamma)
datos_edad <-  datos_edad %>%
  mutate(alpha_post = params.prior[1] + Defunciones,
         beta_post = params.prior[2] + Poblacion,
         theta_post = vec_gamma(1,alpha_post,beta_post))
```

```{r datos por edad}
# graficamos por grupo de edad
datos_edad %>% 
  ggplot() +
  geom_point(aes(x=mortalidad, y = theta_post), size=0.5, alpha=0.5) +
  facet_wrap(vars(GrupoEdad), scale="free")
```
Para el caso de la población con $65$ o más años hay una mayor tasa de mortalidad, lo cual lo hemos observado en resultados previos. Además notemos que para cada grupo de edad tenemos valores atípicos.

**Pregunta 18)** Para uno de los tres municipios que escogiste anteriormente
utiliza la distribución predictiva posterior para verificar el ajuste del modelo
para los grupos de edad: $[0,3), [18,25) \text{ y } [64, \infty).$ 

```{r simulacion por edad}
# seleccionamos municipios de distintos tamaños de manera aleatoria
pos_chico <- sample(which(full_data_filt$tamanio == 1), 1)
pos_mediano <- sample(which(full_data_filt$tamanio == 2), 1)
pos_grande <- sample(which(full_data_filt$tamanio == 3), 1)

# obtenemos su informacion
chico <- paste0(full_data[pos_chico,'entidad'], 
                full_data[pos_chico,'municipio'])
mediano <- paste0(full_data[pos_mediano,'entidad'],
                  full_data[pos_mediano,'municipio'])
grande <- paste0(full_data[pos_grande,'entidad'], 
                 full_data[pos_grande,'municipio'])

# obtenemos un label para el tamaño
muestra_edad <- datos_edad %>% 
  mutate(region = paste0(entidad, municipio)) %>% 
  filter(region == chico | region==mediano | region==grande) %>% 
  mutate(tamano = factor(ifelse(region==chico,
                         "chico",
                         ifelse(region==mediano, "mediano", "grande")),
                         levels = c("chico", "mediano", "grande")))

# replicamos la informacion  para posteriormente simular
res = muestra_edad
for (i in 1:1000){
  res = rbind(res, muestra_edad)
} 
  vec_bn <- Vectorize(rnbinom)

# simulamos
res <- res %>% 
  mutate(sim = vec_bn(1,  size = Poblacion*(params.prior[1])+Defunciones,
                           prob = (params.prior[2]+1)/(params.prior[2]+1+1)))
```


```{r Municipio grande}
# analizamos municipio grande
res %>% 
  filter(tamano == "grande") %>% 
  ggplot() +
  geom_histogram(aes(x=sim)) +
  facet_wrap(~GrupoEdad, scale = "free")

# muestra_edad %>% filter(tamano=="grande")

```


```{r Municipio mediano}
# analizamos municipio mediano
res %>% 
  filter(tamano == "mediano") %>% 
  ggplot() +
  geom_histogram(aes(x=sim)) +
  facet_wrap(~GrupoEdad, scale = "free")

muestra_edad %>% filter(tamano=="mediano")

```

```{r Municipio chico}
# analizamos municipio chico
res %>% 
  filter(tamano == "chico") %>% 
  ggplot() +
  geom_histogram(aes(x=sim)) +
  facet_wrap(~GrupoEdad, scale = "free")

# muestra_edad %>% filter(tamano=="chico")

```

Uno podría asustarse al observar esta gráfica, ya que, la simulación indica que los grupos de edad de los adultos jóvenes tendrán una mayor cantidad de defunciones, sin embargo, no olvidemos que también dichos grupos son los que poseen una mayor cantidad de población. Lo alarmante son para los grupos con "poca" población como es el aso de los bebés (0 a 2 años) y gente mayor (mayores a 65 años).


## Conclusiones: 

¡El último modelo (edad-municipio) incorpora alrededor de 17K parámetros
distintos! Sin duda, no es parsimonioso. De hecho, este modelo representa el
extremo en complejidad para esta situación. Podemos incorporar una estructura
jerárquica donde podemos interpretar una estructura multi-nivel en cuanto
al conocimiento que podemos generar. Esto es por que en la estuctura de
dependencia dejamos la misma distribucion previa sin importar municipio o grupo
de edad. En cursos posteriores exploraremos estas opciones. Pero ahora, ¡a
descansar!

